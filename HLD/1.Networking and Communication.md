Agenda
1. [IP Addressing](#ip-addressing)

    i. [IPv4](#ipv4---internet-protocol-version-4)

    ii. [IPv6](#ipv6---internet-protocol-version-6)
2. [NAT (Public and private IPs)](#nat-public-and-private-ips)
3. Static and Dynamic IPs
4. ICANN
5. DNS
6. Vertical and Horizontal Scaling
7. [Load Balancer](#load-balancer)
   
    i. [Why Load Balancer is needed?](#why-load-balancer-is-needed)
   
    ii. [Type of Load balancers](#type-of-load-balancers)
    
    iii. [Load Balancing Strategies](#load-balancing-strategies)
    
    a. Static Load Balancing
    
    b. Dynamic Load Balancing 
 
     iv. [How LB works](#how-load-balancer-works)
8. [API Gateway](#api-gateway)

    i. [RateLimiting](#ratelimiting)
    
    ii. [Throttling](#throttling)
9. [Sharding](#sharding)


### IP Addressing
IP Address is a unique identifier assigned to each device connected to a network that uses the Internet Protocol
#### IPv4 - Internet Protocol Version 4
1. 32-bit address format 
2. Total 4.3 billion addresses
3. Written in decimal format (e.g.,192.123.1.1)
4. Challenge - Limited IPs, Exhaustion of IPv4 addresses
5. Uses NAT to extend address space

#### IPv6 - Internet Protocol Version 6
1. 128-bit address format
2. Vastly larger address space (3.4 x 10^38 addresses)
3. Written in hexadecimal format (e.g., 2001:0db8:85a3:0000:0000:8a2e:0370:7334)
4. Designed to replace IPv4, addressing exhaustion issues

###  NAT (Public and private IPs)

#### Public Ips
1. Assigned by ISPs
2. Unique across the internet
3. Used for external communication
4. Can be static or dynamic
5. Requires registration with a central authority (IANA/Regional Internet Registries)
6. Examples: Web servers, email servers

#### Private Ips
1. Used within private/local networks
2. Cannot be accessed directly from the internet
3. Ranges defined by RFC 1918
4. Benefits - 
   * Security (if any one know private ip address still system is not assessable for direct use)
   * Scalability (reuse of IPs in different networks)
   * Cost-effective (no need to register with central authority for private IPs)- get one public address and create multiple private IPs using NAT


### Static and Dynamic IPs

### ICANN

### DNS

### Vertical and Horizontal Scaling

### Load Balancer
    A Load Balancer is a critical component in systems that distribute network or application traffic across multiple servers. Its primary purpose is to ensure that no single server becomes overwhelmed with too many requests, thereby optimizing resource use, maximizing throughput, minimizing response time, and avoiding overload

Load Balancer is a server used to distribute network or application traffic across a number of servers. It helps to improve the responsiveness and availability of applications, websites, or databases by distributing the workload evenly.

#### Why Load Balancer is needed?
1. **High Availability**: Ensures that if one server goes down, the traffic is redirected to other available servers.
2. **Scalability**: Allows adding or removing servers based on demand without affecting the overall system.
3. **Performance**: Distributes traffic evenly to prevent any single server from becoming a bottleneck.
4. **Security**: Can provide an additional layer of security by hiding the internal server structure.    

#### Type of Load balancers
1. Based on Layer
    * Layer 4 Load Balancer - Non Http Client request - Transport Layer (TCP/UDP)
    * Layer 7 Load Balancer - Http Client request - Application Layer (HTTP/HTTPS)
2. Based on Deployment
    * Hardware Load Balancer - F5, Citrix ADC
    * Software Load Balancer - Nginx, HAProxy, Traefik
    * Cloud-based Load Balancer - AWS Elastic Load Balancer, Azure Load Balancer, Google Cloud Load Balancer

#### Load Balancing Strategies
1. **Static Load Balancing** 

Distribute traffic based on predefine rules without considering current server conditions.

These strategies work very well in environment where **server capacities are similar** and **work load is predictable** and consistent.
   
**Techniques**:
   * Round Robin - 

        Distribute requests sequentially across the server pool in circular order. Once last server receive the request the process starts again over first server. 

        This ensures **even distribution of traffic** but **not consider server load or response time** that each server is provided.

   * Least Connections - 

      Direct request to the server with the fewest active connections. 

      This method is effective when there are **varying load levels**(request processing time is very significantly different from each other) across servers, as it helps to balance the traffic based on current server utilization. that means it ensure that highly loaded server will not receive more request until it's clearing the existing request.

   * IP Hashing-

        Client IP address is used to determine which server will handle the request.
        
        Hash Function map each client ip address to a specific server in the server pool. To ensure that requests from the same client are consistently directed to the same server.
            
        This method provides **session persistence** (also known as sticky sessions), ensuring that a client consistently connects to the same server for the duration of their session. This is particularly useful for applications that maintain state information.

**Advantages of static load balancing**:
   * Simple to implement and understand.
   * Low overhead since it does not require real-time monitoring of server load.
   * Effective in environments with predictable and consistent workloads.

**Challenges of static load balancing**:
   * Does not consider real-time server load or performance metrics.
   * Not optimum for the systems with highly variable work load.
   * May lead to uneven distribution if client IPs are not uniformly distributed.

2. **Dynamic Load Balancing**

Unlike static load balancing, dynamic load balancing takes into account the current state(load) of the servers in the pool. 

It monitors various performance metrics such as CPU usage, memory usage, response time, and network latency to make informed decisions about where to route incoming requests.

**Techniques**:
* Least Response Time -         

    Direct request to the server with the lowest response time. 
    
    This method ensures **fastest response time** that means requests are routed to the server that can handle them the fastest, improving overall system responsiveness. Useful in environments where speed is very critical such as real-time applications, financial trading applications, live-streaming video services.

* Adaptive Load Balancing - 
    
    Continuously monitors server performance metrics( CPU usage, memory utilization, server health), and dynamically adjusts the distribution of traffic based on real-time conditions. 
    
    This approach allows for more granular control over traffic distribution, ensuring that servers are utilized optimally based on their current load and performance.

* Weighted Load Balancing - 
       
    Assigns weights to each server based on their capacity and performance. Servers with higher weights receive a larger proportion of the traffic.
    
    This method is particularly useful in heterogeneous environments where servers have varying capabilities.


**Advantages of dynamic load balancing**:
   * More efficient use of server resources by considering real-time load.
   * Better performance and responsiveness, especially in environments with variable workloads.
   * Can adapt to changing conditions, such as server failures or spikes in traffic.

**Challenges of dynamic load balancing**:
   * More complex to implement and manage due to the need for real-time monitoring.
   * Higher overhead from continuous monitoring and decision-making processes.


Static Load Balancing - Round Robin work well
Dynamic Load Balancing - Adaptive Load balancing work well

#### How Load Balancer works
1. How Load Balancer knows about the servers?

On Application startup, Application send a request to Load balancer to register itself. Load balancer maintain a list of all available servers and their status (healthy or unhealthy).

2. How Load Balancer knows server dead?

There are two ways:
   * Health Check Endpoint - Load balancer periodically(x) send request to each server's health check endpoint (like /health or /status). If server respond with success status code (200 OK), it's considered healthy. If it fails to respond or returns error status code (500, 503), it's marked as unhealthy.
   * Heartbeat Mechanism - Servers send periodic(x) heartbeat signals to load balancer to indicate they are alive. If load balancer does not receive heartbeat within specified time (y), it marks server as unhealthy.

3. How load balancer distributes the request to servers?
   
Depends on the above mention techniques and strategies like Round Robin, Least Connections, IP Hashing, Least Response Time, Adaptive Load Balancing, Weighted Load Balancing.


### API Gateway

#### RateLimiting 
Restricts the number of requests a client can make to an API within a specified time frame to prevent abuse and ensure fair usage.

#### Throttling 
Control traffic during peak load to maintain system performance and availability by limiting the number of requests processed.

Ratelimiting and Throttling are often used together to manage API traffic effectively. It is majorly used when multiple api uses the api at scale

### Caching
Speed up the API responses by storing frequently accessed data closer to the client, reducing latency and server load.

Type of caching:
1. Client-Side Caching - Data is stored on the client device (browser or application) to reduce the need for repeated requests to the server.
2. Server-Side Caching - Data is stored on the server to quickly serve repeated requests without reprocessing.
3. Distributed Caching - Data is stored across multiple servers or nodes to improve scalability and fault tolerance.

### Sharding
A database partitioning technique that divides a large database(unable to fit in one machine) into smaller, more manageable pieces called shards, each hosted on a separate database server to improve performance and scalability.

Sharding is simply "Horizontal Partitioning across server".

Which data in which machine is decided by developer or system designer based on the sharding key.

Objective of sharding:
1. Improve performance by distributing the load across multiple servers.
2. Enhance scalability by allowing the system to grow by adding more servers.
3. Increase availability by isolating failures to individual shards.
4. Reduce latency by placing shards closer to users geographically.
5. Optimize resource utilization by balancing the data and workload across servers.
6. Facilitate easier maintenance and management of large datasets.
7. Enable handling of large volumes of data that exceed the capacity of a single server.
8. Support high-throughput applications by distributing read and write operations across multiple shards.
9. Efficient Query Execution.

#### Sharding Key: Attribute or set of attributes used to determine how data is distributed across shards.(in which shrad a particular row will go)

#### Types of Sharding:
1. Range-Based Sharding - Data is divided based on ranges of a specific attribute (e.g., user ID ranges).

Possible Example: Users with IDs 1-1000 go to Shard 1, 1001-2000 go to Shard 2, and so on.

Pros:
* Simple to implement and understand.
* Efficient for range queries.
* Easy to scale by adding new shards for new ranges.

Cons:
* Can lead to uneven data distribution if ranges are not well-defined.
* Hotspots may occur if certain ranges receive significantly more traffic.
* Rebalancing shards can be complex if data distribution changes over time.

When to use:
   * When data can be logically divided into ranges.
   * When queries often target specific ranges of data.
   * When there is a need for ordered data retrieval.

Real applications:
   * Time-series data (e.g., logs, sensor data)
   * E-commerce platforms (e.g., product IDs, order dates)
   * Social media applications (e.g., user IDs, post timestamps)

2. Hash-Based Sharding - A hash function is applied to a specific attribute to determine the shard placement.
Possible Example: A hash function is applied to the user ID, and the result determines which shard the data goes to.
Pros:
* Provides a more uniform data distribution.
* Reduces the likelihood of hotspots.
* Easier to scale by adding new shards and rehashing data.
* Handles high write loads effectively.
* Good for workloads with random access patterns.
* Minimizes data skew.
* Facilitates load balancing across shards.
* Simplifies shard management.
* Supports high concurrency.
* Enables efficient use of storage resources.
* Improves fault tolerance by distributing data evenly.
* Enhances performance for read and write operations.

Cons:
* More complex to implement due to the need for a hash function.
* Can make range queries less efficient.
* Rehashing may be required when adding or removing shards.

When to use:
   * When uniform data distribution is critical.
   * When the workload involves random access patterns.
   * When scalability and load balancing are priorities.

Real applications:
   * Large-scale web applications (e.g., user profiles, session data)
   * Content delivery networks (e.g., caching content based on URL hashes)
   * Distributed databases (e.g., NoSQL databases like Cassandra, MongoDB)

3. Directory-Based Sharding - A lookup table is maintained to map data to specific shards.

Possible Example: A directory maps user IDs to specific shards based on predefined rules.

Pros:
* Provides flexibility in data distribution.
* Allows for complex sharding strategies.
* Easy to change shard assignments without rehashing data.
* Facilitates dynamic shard management.
* Enables fine-grained control over data placement.
* Supports heterogeneous shard configurations.
* Simplifies data migration between shards.
* Enhances data locality for specific access patterns.

Cons:
* Introduces additional overhead for maintaining the directory.
* Can become a bottleneck if the directory is not efficiently managed.
* Increases complexity in shard management.
* Requires careful design to avoid single points of failure.

When to use:
   * When data distribution needs to be highly customizable.
   * When shard assignments may change frequently.
   * When complex access patterns require specific data placements.

Real applications:
   * Multi-tenant applications (e.g., SaaS platforms with varying tenant requirements)
   * Applications with dynamic data distribution needs (e.g., gaming platforms)
   * Content management systems (e.g., CMS with diverse content types)
4. Composite Sharding - Combines multiple sharding strategies to optimize data distribution.

Possible Example: Using range-based sharding for user IDs and hash-based sharding for session data

Pros:
* Leverages the strengths of multiple sharding techniques.
* Provides flexibility in handling diverse data types.
* Optimizes performance for different access patterns.
* Enhances scalability by combining strategies.
* Improves fault tolerance by diversifying data distribution methods.
* Enables tailored data placement for specific workloads.
* Facilitates efficient resource utilization across shards.
* Supports complex application requirements.
* Enhances overall system performance by optimizing data access.

Cons:
* Increases complexity in implementation and management.
* Requires careful planning to avoid conflicts between sharding strategies.
* May introduce additional overhead in shard management.
* Requires sophisticated monitoring to ensure optimal performance.

When to use:
   * When dealing with diverse data types and access patterns.
   * When single sharding strategies do not meet performance requirements.
   * When scalability and flexibility are critical.

Real applications:
   * E-commerce platforms (e.g., combining product and user data sharding)
   * Social media applications (e.g., combining user profiles and content data sharding)
   * Educational platforms (e.g., combining student and course data sharding)

5. Geo-Based Sharding - Data is partitioned based on geographical location to reduce latency for users in different regions.

Possible Example: Users from North America are directed to Shard 1, while users from Europe are directed to Shard 2.

Pros:
* Reduces latency by placing data closer to users.
* Improves performance for geographically distributed user bases.
* Enhances user experience by minimizing response times.
* Facilitates compliance with data residency regulations.
* Supports localized data management.
* Enables efficient handling of region-specific workloads.
* Improves fault tolerance by isolating regional failures.

Cons:
* Can lead to uneven data distribution if user bases are not evenly spread.
* Requires careful management of data synchronization across regions.
* May introduce complexity in shard management due to geographical considerations.
* Requires robust infrastructure to support global distribution.

When to use:
   * When serving a global user base with significant geographical distribution.
   * When latency reduction is a priority for user experience.
   * When compliance with regional data regulations is necessary.

Real applications:
   * Global e-commerce platforms (e.g., Amazon, eBay)
   * Social media networks (e.g., Facebook, Twitter)
   * Content delivery networks (e.g., Akamai, Cloudflare)
   * Online gaming platforms (e.g., Fortnite, PUBG)
   * Video streaming services (e.g., Netflix, YouTube)
   * Cloud service providers (e.g., AWS, Azure, Google Cloud)
   * Financial services (e.g., international banking platforms)
   * Travel and booking platforms (e.g., Airbnb, Booking.com)
   * News and media websites (e.g., BBC, CNN)
   * Educational platforms with global reach (e.g., Coursera, edX)
   * Healthcare platforms serving multiple regions (e.g., telemedicine services)
   * Collaboration tools (e.g., Slack, Microsoft Teams)
   * Ride-sharing services (e.g., Uber, Lyft)
   * Food delivery services (e.g., Uber Eats, DoorDash)
   * Online marketplaces (e.g., Etsy, Alibaba)
   * Real-time communication platforms (e.g., Zoom, Skype)
   * Cloud-based productivity suites (e.g., Google Workspace, Microsoft 365)
   * Online forums and communities (e.g., Reddit, Stack Overflow)
   * E-learning platforms with international users (e.g., Duolingo, Khan Academy)
   * Virtual event platforms (e.g., Hopin, Eventbrite)
   * Remote work platforms (e.g., GitHub, GitLab)
   * Global logistics and supply chain platforms (e.g., FedEx, DHL)

Summary/ Table having different type of Sharding and when to use and when to avoid with real applications:

| Sharding Type        | When to Use                                         | When to Avoid                                      | Real Applications                                  |
|----------------------|-----------------------------------------------------|----------------------------------------------------|---------------------------------------------------|
| Range-Based Sharding | Logical data ranges, range queries                  | Uneven data distribution, hotspots                    | Time-series data, e-commerce, social media        |
| Hash-Based Sharding | Uniform distribution, random access patterns       | Complex implementation, inefficient range queries   | Web applications, CDNs, distributed databases |
| Directory-Based Sharding | Customizable distribution, dynamic shard assignments | Directory overhead, single points of failure          | Multi-tenant apps, dynamic data distribution, CMS  |
| Composite Sharding | Diverse data types, complex access patterns         | Increased complexity, management overhead           | E-commerce, social media, educational platforms |
| Geo-Based Sharding  | Global user base, latency reduction                     | Uneven distribution, data synchronization complexity | Global e-commerce, social media, CDNs            |


#### Sharding Algorithms: Tell in which Shard the data will go

1.Modulo: Example: Sharding key is user_id and we have 4 shard (machine)

  getShared(user_id) =user_id % number_of_shards

Pros: Simple
      Uniform Distribution if sharding key is uniformly distributed

Cons: scalability issue - when we add or remove the shard we need to do lot of data transfer between Shards.

2.Range-Based: Define ranges for each shard like 0-250 to Shard 1, 251-500 to Shard 2 so on....

Pros: Simple to implement and understand.
      Efficient for range queries.
      Easy to scale by adding new shards for new ranges.

Cons: Can lead to uneven data distribution if ranges are not well-defined.
      Hotspots may occur if certain ranges receive significantly more traffic.
      Rebalancing shards can be complex if data distribution changes over time.

3. Consistent Hashing: Use a hash function to map both data and shards to a circular space. Data is assigned to the nearest shard in the clockwise direction.

Pros: Scalability - Adding or removing a shard only affects a small portion of the data.
      Reduces data movement during scaling operations.
      Provides a more uniform data distribution.

Cons: Reduce load of only one Shared.
      More complex to implement.
      May require virtual nodes to improve distribution.
      Can make range queries less efficient.

When to use: When scalability is a priority.
                 When dealing with dynamic shard membership.
                 When uniform data distribution is critical.

4. Optimized Consistent Hashing: An enhanced version of consistent hashing that incorporates virtual nodes and load balancing techniques to further optimize data distribution and minimize hotspots.
* This is used by MangoDB internally
* Use Multiple hash function to find number of shard for a particular key. and load he data on all those Shards.

5. Dynamic Sharding Algorithms: Algorithms that adapt to changing data patterns and workloads in real-time, optimizing shard assignments based on current system conditions.
6. Machine Learning-Based Sharding: Utilizing machine learning techniques to predict data access patterns and optimize

#### Sharding vs Replication


#### Summary of Sharding Algorithms:

| Sharding Algorithm        | Speed          | Uniform Distribution | Scalability     | Complexity      |
|---------------------------|----------------|----------------------|-----------------|-----------------|
| Modulo        | Fast          | Uniform Distribution | NA     | Simple     |
| Range Based          | Fast          | NA | Add and remove easy     | Simple      |
| Consistent Hashing       | Moderate       | Good                 | High            | Moderate        |



### Caching
        Storing of copy data at some another space so that next time when same data is requested it can be fetched from cache instead of original data source which is time consuming.
        It can be done on same machine or different machine.

#### Caching Vs Backup

| Aspect           | Caching                                                   | Backup                                                       |
|------------------|-----------------------------------------------------------|--------------------------------------------------------------|
| Purpose          | Improve performance and reduce latency                    | Data recovery and protection                                 |
| Data Freshness   | Typically stores recent or frequently accessed data       | Stores complete data snapshots at  specific points in time   |
| Storage Location | Can be on the same machine or separate cache servers      | Usually stored on separate storage systems or cloud services |
| Data Volume      | Generally smaller, focused on frequently accessed data    | Can be large, encompassing entire datasets                   |
| Access Speed     | Fast access for quick retrieval                           | Slower access, optimized for durability                      |
| Update Frequency | Frequently updated to reflect current data                | Updated periodically, often less frequently                  |
| Data Retention   | Short-term storage, data may be evicted                   | Long-term storage, data is preserved for recovery            |
| Use Cases        | Web applications, databases, content delivery networks    | Disaster recovery, archival, compliance                      |
| Examples         | In-memory caches (Redis, Memcached), CDN caches           | Backup solutions (AWS Backup, Veeam, Acronis)                |
| Frequency        | Real-time or near real-time                               | Scheduled or on-demand                                       |
| Data Consistency | May allow stale data for performance                      | Ensures data integrity and consistency                       |
| Cost             | Generally lower cost due to smaller storage needs         | Can be higher due to larger storage requirements             |
| Complexity       | Relatively simple to implement and manage                 | Can be complex, especially for large datasets                |
| Recovery Time    | Immediate access to cached data                           | May require time to restore data from backup                 |
| Data Type        | Frequently accessed data                                  | Complete datasets or critical files                          |
| Security         | May have basic security measures                          | Often includes robust security and encryption                |
| Management       | Typically managed by application or system administrators | Managed by IT or backup specialists                          |
| Scalability      | Easily scalable to handle increased load                  | Scalability depends on backup infrastructure                 |
| Data Format      | Often unstructured or semi-structured data                | Can include structured, unstructured, or binary data         |

#### Caching Types:
1. In-Memory Caching - Data is stored in RAM for ultra-fast access.(DNS Ipaddress,Google Typehead search suggestions)
2. In-Browser Caching - Web browsers store static resources locally to speed up page load times (e.g., HTML, CSS, JavaScript files).
2. Distributed Caching - Data is stored across multiple servers to improve scalability and fault tolerance (e.g., Amazon ElastiCache, Apache Ignite).
3. Content Delivery Network (CDN) Caching - Static content is cached at edge locations to reduce latency for users (e.g., Cloudflare, Akamai). 
   * If application server is accessing the data then we don't use CDN since request will come from server only not users.
   * CDN gives good User Experience
   * Reduces Latency
   * CDN is expensive
4. Application-Level Caching - Specific data or computations are cached within the application logic with additional metadata. (e.g., memoization in functions).
5. Global Caching - Caching at centralised location to be accessed by multiple applications or services. ex(Redis)

Problem with caching: 
* **Cache Invalidation** - Ensuring that cached data is updated or removed when the underlying data changes.
* **Cache Consistency** - Maintaining consistency between the cache and the original data source.
* **Cache Eviction** - Deciding which data to remove from the cache when it reaches its capacity.
* Cache Stampede - Preventing multiple requests from overwhelming the cache when a popular item expires.
* Latency - Network latency can impact the performance of distributed caches.

#### Solution of cache consistency:
1. Time-to-Live (TTL) - 

* Cached data is assigned an expiration time after which it is invalidated.
* After specific time period data will be removed from cache automatically or mark it invalid.
* It will gain synchronicity after specific time period when new request come and data is fetched from original data source.
* If TTL is 1min, that means data will be valid for 1 min only after that cache will not allow to red that data.
* Suitable for data that changes infrequently.
        
Pros:
* Simple to implement.
* Reduces stale data issues.
* Data read is fast as its read from cache first then DB.
        
Cons:
* May lead to unnecessary cache misses if data is still valid.
* Not suitable for data that changes frequently.
        
When To use:
* When speed have more priority over consistency. Like in news feed application we can show slightly old data.
* When data changes infrequently.
* When some staleness is acceptable.
* When simplicity is a priority.

Write Strategies:

   2.a.    **Write-Through Cache** - 
* Data is written to both the cache and the underlying data store simultaneously.
* Data will write in cache first then in original data source. and mark success only after both operation is successful.
* Ensures data consistency between cache and original data source.
* Suitable for applications where data consistency is critical.

Pros:
* Ensures strong consistency between cache and data store.
* Simplicity in implementation.
                
Cons:
* Higher write latency due to dual writes.

When to Use :
* When data consistency is critical.
* When write latency is acceptable.
* When simplicity is a priority.

When Not to Use:

* When write performance is critical.
* When dealing with high write loads.
* CDN (Not possible to update Image at all Cache first the original source) and In Browing caching (same not possble to update data at all client browser Cache first)

Real applications: Banking systems, Inventory management systems.

   2.b.    **Write-Around Cache** - Data is written to the Database directly, bypassing the cache done. The cache is only updated on read operations. using TTL approach.

Pros:
* Reduces write load on the cache.
* Suitable for write-heavy workloads where data is infrequently read.

Cons:
* May lead to cache misses on subsequent reads.
* Increased read latency for uncached data.

When to Use:
* When write load is high and read load is low.
* When data is infrequently read after being written.
* When cache size is limited.
* Real applications: Logging systems, Analytics data storage.

2.c.    **Write-Back (Write-Behind) Cache** - Data is written to the cache Done and then asynchronously to the underlying data store. Sync Db at every xmin
Pros:
* Improves write performance by reducing latency.
* Suitable for write-heavy workloads.
* Cache is always latest data.
Cons:
* Risk of data loss if cache fails before data is written to the data store.
* Increased complexity in implementation.
* Data consistency challenges.

When to Use:
* When write performance is critical.
* When eventual consistency is acceptable.
* When dealing with high write loads. 

Real Application - Host star live view counting system

create a table having 6 column and 4 rows showing Strategy, Description,Speed of write,speed of read,consistency,usecase 

| Strategy      | Description                                                               | Speed of Write | Speed of Read | Consistency         | Use Case                               |
|---------------|---------------------------------------------------------------------------|------------|---------------|---------------------|----------------------------------------|
| TTL           | Application checks cache first; if data is not found, retrieves from DB   | Moderate   | Fast          | Eventual            | Frequently accessed data               |
| Read-Through  | Cache automatically loads data from DB on a cache miss                    | Fast       | Fast          |                     | Read-heavy workloads                   |
| Write-Through | Data is written to both cache and then DB simultaneously and mark as done | Slow       | Fast          | Strong              | Data consistency critical applications |
| Write-Around  | Data is written to Database.                                              | Moderate   | Moderate      | Eventual            |                                        |
| Write-Back    | Data is written to cache.                                                 | Fast       | Fast          | Eventual(Data lost) | Write-heavy workloads view count       |   

#### Solution of cache size limit:
Cache Eviction Policies - Implementing strategies to determine which data to remove from the cache when it reaches its capacity.

Algorithms:
   * FIFO (First In, First Out) - Removes the oldest items first.
   * LRU (Least Recently Used) - Removes the least recently accessed items first. Best and always used
   * LIFO (Last In, First Out) - Removes the most recently added items first.
   * LFU (Least Frequently Used) - Removes the least frequently accessed items first. In case of Tie apply FIFO
   


