Agenda
1. [IP Addressing](#ip-addressing)

    i. [IPv4](#ipv4---internet-protocol-version-4)

    ii. [IPv6](#ipv6---internet-protocol-version-6)
2. [NAT (Public and private IPs)](#nat-public-and-private-ips)
3. Static and Dynamic IPs
4. ICANN
5. DNS
6. Vertical and Horizontal Scaling
7. [Load Balancer](#load-balancer)
   
    i. [Why Load Balancer is needed?](#why-load-balancer-is-needed)
   
    ii. [Type of Load balancers](#type-of-load-balancers)
    
    iii. [Load Balancing Strategies](#load-balancing-strategies)
    
    a. Static Load Balancing
    
    b. Dynamic Load Balancing 
 
     iv. [How LB works](#how-load-balancer-works)
8. [API Gateway](#api-gateway)

    i. [RateLimiting](#ratelimiting)
    
    ii. [Throttling](#throttling)
9. [Sharding](#sharding)


### IP Addressing
IP Address is a unique identifier assigned to each device connected to a network that uses the Internet Protocol
#### IPv4 - Internet Protocol Version 4
1. 32-bit address format 
2. Total 4.3 billion addresses
3. Written in decimal format (e.g.,192.123.1.1)
4. Challenge - Limited IPs, Exhaustion of IPv4 addresses
5. Uses NAT to extend address space

#### IPv6 - Internet Protocol Version 6
1. 128-bit address format
2. Vastly larger address space (3.4 x 10^38 addresses)
3. Written in hexadecimal format (e.g., 2001:0db8:85a3:0000:0000:8a2e:0370:7334)
4. Designed to replace IPv4, addressing exhaustion issues

###  NAT (Public and private IPs)

#### Public Ips
1. Assigned by ISPs
2. Unique across the internet
3. Used for external communication
4. Can be static or dynamic
5. Requires registration with a central authority (IANA/Regional Internet Registries)
6. Examples: Web servers, email servers

#### Private Ips
1. Used within private/local networks
2. Cannot be accessed directly from the internet
3. Ranges defined by RFC 1918
4. Benefits - 
   * Security (if any one know private ip address still system is not assessable for direct use)
   * Scalability (reuse of IPs in different networks)
   * Cost-effective (no need to register with central authority for private IPs)- get one public address and create multiple private IPs using NAT


### Static and Dynamic IPs

### ICANN

### DNS

### Vertical and Horizontal Scaling

### Load Balancer
    A Load Balancer is a critical component in systems that distribute network or application traffic across multiple servers. Its primary purpose is to ensure that no single server becomes overwhelmed with too many requests, thereby optimizing resource use, maximizing throughput, minimizing response time, and avoiding overload

Load Balancer is a server used to distribute network or application traffic across a number of servers. It helps to improve the responsiveness and availability of applications, websites, or databases by distributing the workload evenly.

#### Why Load Balancer is needed?
1. **High Availability**: Ensures that if one server goes down, the traffic is redirected to other available servers.
2. **Scalability**: Allows adding or removing servers based on demand without affecting the overall system.
3. **Performance**: Distributes traffic evenly to prevent any single server from becoming a bottleneck.
4. **Security**: Can provide an additional layer of security by hiding the internal server structure.    

#### Type of Load balancers
1. Based on Layer
    * Layer 4 Load Balancer - Non Http Client request - Transport Layer (TCP/UDP)
    * Layer 7 Load Balancer - Http Client request - Application Layer (HTTP/HTTPS)
2. Based on Deployment
    * Hardware Load Balancer - F5, Citrix ADC
    * Software Load Balancer - Nginx, HAProxy, Traefik
    * Cloud-based Load Balancer - AWS Elastic Load Balancer, Azure Load Balancer, Google Cloud Load Balancer

#### Load Balancing Strategies
1. **Static Load Balancing** 

Distribute traffic based on predefine rules without considering current server conditions.

These strategies work very well in environment where **server capacities are similar** and **work load is predictable** and consistent.
   
**Techniques**:
   * Round Robin - 

        Distribute requests sequentially across the server pool in circular order. Once last server receive the request the process starts again over first server. 

        This ensures **even distribution of traffic** but **not consider server load or response time** that each server is provided.

   * Least Connections - 

      Direct request to the server with the fewest active connections. 

      This method is effective when there are **varying load levels**(request processing time is very significantly different from each other) across servers, as it helps to balance the traffic based on current server utilization. that means it ensure that highly loaded server will not receive more request until it's clearing the existing request.

   * IP Hashing-

        Client IP address is used to determine which server will handle the request.
        
        Hash Function map each client ip address to a specific server in the server pool. To ensure that requests from the same client are consistently directed to the same server.
            
        This method provides **session persistence** (also known as sticky sessions), ensuring that a client consistently connects to the same server for the duration of their session. This is particularly useful for applications that maintain state information.

**Advantages of static load balancing**:
   * Simple to implement and understand.
   * Low overhead since it does not require real-time monitoring of server load.
   * Effective in environments with predictable and consistent workloads.

**Challenges of static load balancing**:
   * Does not consider real-time server load or performance metrics.
   * Not optimum for the systems with highly variable work load.
   * May lead to uneven distribution if client IPs are not uniformly distributed.

2. **Dynamic Load Balancing**

Unlike static load balancing, dynamic load balancing takes into account the current state(load) of the servers in the pool. 

It monitors various performance metrics such as CPU usage, memory usage, response time, and network latency to make informed decisions about where to route incoming requests.

**Techniques**:
* Least Response Time -         

    Direct request to the server with the lowest response time. 
    
    This method ensures **fastest response time** that means requests are routed to the server that can handle them the fastest, improving overall system responsiveness. Useful in environments where speed is very critical such as real-time applications, financial trading applications, live-streaming video services.

* Adaptive Load Balancing - 
    
    Continuously monitors server performance metrics( CPU usage, memory utilization, server health), and dynamically adjusts the distribution of traffic based on real-time conditions. 
    
    This approach allows for more granular control over traffic distribution, ensuring that servers are utilized optimally based on their current load and performance.

* Weighted Load Balancing - 
       
    Assigns weights to each server based on their capacity and performance. Servers with higher weights receive a larger proportion of the traffic.
    
    This method is particularly useful in heterogeneous environments where servers have varying capabilities.


**Advantages of dynamic load balancing**:
   * More efficient use of server resources by considering real-time load.
   * Better performance and responsiveness, especially in environments with variable workloads.
   * Can adapt to changing conditions, such as server failures or spikes in traffic.

**Challenges of dynamic load balancing**:
   * More complex to implement and manage due to the need for real-time monitoring.
   * Higher overhead from continuous monitoring and decision-making processes.


Static Load Balancing - Round Robin work well
Dynamic Load Balancing - Adaptive Load balancing work well

#### How Load Balancer works
1. How Load Balancer knows about the servers?

On Application startup, Application send a request to Load balancer to register itself. Load balancer maintain a list of all available servers and their status (healthy or unhealthy).

2. How Load Balancer knows server dead?

There are two ways:
   * Health Check Endpoint - Load balancer periodically(x) send request to each server's health check endpoint (like /health or /status). If server respond with success status code (200 OK), it's considered healthy. If it fails to respond or returns error status code (500, 503), it's marked as unhealthy.
   * Heartbeat Mechanism - Servers send periodic(x) heartbeat signals to load balancer to indicate they are alive. If load balancer does not receive heartbeat within specified time (y), it marks server as unhealthy.

3. How load balancer distributes the request to servers?
   
Depends on the above mention techniques and strategies like Round Robin, Least Connections, IP Hashing, Least Response Time, Adaptive Load Balancing, Weighted Load Balancing.


### API Gateway

#### RateLimiting 
Restricts the number of requests a client can make to an API within a specified time frame to prevent abuse and ensure fair usage.

#### Throttling 
Control traffic during peak load to maintain system performance and availability by limiting the number of requests processed.

Rate limiting and Throttling are often used together to manage API traffic effectively. It is majorly used when multiple api uses the api at scale

### Caching
Speed up the API responses by storing frequently accessed data closer to the client, reducing latency and server load.


